# Summary

* [Introduction](README.md)
* [第2章 感知机 - 原始形式](Chapter2/perceptron.md)
    * [学习策略的推导](Chapter2/1.md)
    * [梯度下降法的算法过程](Chapter2/2.md)
    * [梯度下降法的推导过程](Chapter2/3.md)
    * [梯度下降法的收敛证明](Chapter2/4.md)
* [第2章 感知机 - 对偶形式](Chapter2/perceptron2.md)
    * [学习模型的推导](Chapter2/5.md)
    * [梯度下降法的算法过程](Chapter2/6.md)
    * [梯度下降法的推导过程](Chapter2/7.md)
* [第3章 k近邻算法](Chapter3/KNN.md)
    * [模型三要素](Chapter3/1.md)
    * [构造平衡kd树](Chapter3/2.md)
    * [用kd树的k近邻搜索](Chapter3/3.md)
* [第4章 朴素贝叶期](Chapter4/NaiveteBayes.md)
    * [模型公式的推导](Chapter4/1.md)
    * [策略公式的推导](Chapter4/2.md)
    * [最大似然估计算法过程](Chapter4/3.md)
    * [贝叶斯估计算法过程](Chapter4/4.md)
* [第5章 决策树](Chapter5/DecisionTree.md)
    * [决策树的模型](Chapter5/1.md)
    * [信息增益的算法](Chapter5/2.md)
    * [ID3决策树的生成算法](Chapter5/3.md)
    * [C4.5决策树的生成算法](Chapter5/4.md)
    * [决策树的剪枝算法](Chapter5/5.md)
* [第5章 CART决策树](Chapter5/CART.md)
    * [CART树的生成](Chapter5/6.md)
    * [CART树的剪枝](Chapter5/7.md)
* [第6章 逻辑回归](Chapter6/LogisticRegression.md)
    * [二分类逻辑回归模型](Chapter6/1.md)
    * [多分类逻辑回归模型](Chapter6/2.md)
* [第6章 最大熵模型](Chapter/maximum.md)
    * [最大熵的原理](Chapter6/3.md)
    * [最大熵模型的定义](Chapter6/4.md)
    * [最大熵的学习过程](Chapter6/5.md)
    * [根据最大熵的学习过程推导最大熵模型](Chapter6/6.md)
    * [证明：对偶函数的极大化=模型的极大似然估计](Chapter6/7.md)
* [第6章 目标函数最优化问题](Chapter6/option.md)
    * [改进的迭代尺度法（IIS）](Chapter6/8.md)
    * [IIS算法公式（1）推导](Chapter6/9.md)
    * [A和B的推导](Chapter9/10.md)
    * [拟牛顿法](Chapter6/11.md)
* [第7章 支持向量机](Chapter7/svm.md)
    * [函数间隔与几何间隔](Chapter7/1.md)
* [第7章 线性可分SVM](Chapter7/2.md)
    * [凸二次规划问题推导](Chapter7/3.md)
    * [支持向量](Chapter7/4.md)
    * [凸二次规划问题求解](Chapter7/5.md)
    * [原始问题转换为对偶最优化问题](Chapter7/6.md)
* [第7章 线性SVM](Chapter7/7.md)
    * [原始问题转换为对偶最优化问题](Chapter7/8.md)
    * [根据 a* 求 w* 和 b*](Chapter7/9.md)
    * [支持向量](Chapter7/10.md)
* [第7章 非线性SVM](Chapter7/11.md)
    * [核函数与核技巧](Chapter7/12.md)
    * [核技巧在SVM中的应用](Chapter7/13.md)
    * [7.3.2 正定核](Chapter7/14.md)
    * [常用的核函数](Chapter7/15.md)
* [第7章 序列最小最优化算法](Chapter7/smo.md)
    * [选择变量](Chapter7/16.md)
    * [推导1](Chapter7/17.md)
    * [推导2](Chapter7/18.md)
    * [推导3](Chapter7/19.md)
    * [推导4](Chapter7/20.md)
    * [推导5：update b](Chapter7/21.md)
* [第8章 adaboost](Chapter8/adaboost.md)
    * [算法过程](Chapter8/1.md)
    * [训练误差分析](Chapter8/2.md)
    * [加法模型](Chapter8/3.md)
    * [前向分步算法](Chapter8/4.md)
    * [adaboost一种特殊的加法模型](Chapter8/5.md)
* [第8章 提升树](Chapter8/BoostingTree.md)
    * [回归问题提升树的推导](Chapter8/6.md)
    * [回归问题提升树前向分步算法](Chapter8/7.md)
    * [一般决策问题梯度提升算法](Chapter8/8.md)
* [第9章 EM算法](Chapter9/em.md)
    * [算法过程](Chapter9/1.md)
    * [Q函数的推导](Chapter9/2.md)
* [遗留问题](question.md)