# 朴素贝叶斯算法

输入：  
样本数据T，包含m个n维特征的样本。  
aij为每个样本特征的第i个特征可取到的第j个值。  
测试样本x  
输出：  
对x的预测分类。  

## 计算先验概率
$$
P_k(Y=C_k) = \frac {\sum I(y=C_k)}{m}
$$

## 计算每个特征每个取值的条件概率
$$P_{ijk}$$为当$$y=C_k$$时，X第j个特征为$$a_{ij}$$的条件概率  

$$
P_{ijk} = \frac{\sum I(X^{(i)} = a_{ij}, y=C_k)}{\sum I(y=C_k)}
$$

## 计算假如$$y=C_k$$时出现X=x的条件概率

对所有$$C_k$$计算$$P(X=x|Y=C_k)$$  
$$P(X=x|Y=C_k)$$为当$$y=C_k$$时，x的每一个特征的条件概率的乘积。  
$$
P(X=x|Y=C_k) = \prod P(x^{(i)}=a_i|y=C_k)
$$

## 计算当X=x时所有$$C_k$$的后验概率的分子
$$
P(Y=C_k|X=x) = \frac{P(X=x|Y=C_k)P(Y=C_k)}{P(X=x)}
$$
以上公式中分子所有需要的内容都在以前已经计算出，代入公式即可  
不需要计算分母。因为最终要用到的不是后验概率的具体数值，只是要比较大小。中所有C_k的后验概率公式，分母都是相同的，不影响大小的比较，所以不用计算出来。  

## 确定x的分类

当X=x时所有$$C_k$$的后验概率中分子取得最大概率的那$$C_k$$即x的分类

# 代码

```python
def NaiveteBayes(T, y, a, Y, x):
    # 计算先验概率
    prepro = {}
    for yRange in Y:
        #print (yRange, Y[Y==yRange].shape[0], )
        prepro[yRange] = y[y==yRange].shape[0]/y.shape[0]
    print('先验概率：',prepro)
    # 计算条件概率
    conpro = {}
    for i in range(len(a)):  # 遍历每个特征
        for j in a[i]: # 遍历特征的每个取值
            for k in Y:
                conpro[(i,j, k)] = X[(y==k)&(X[:,i]==j),:].shape[0]/X[y==k,:].shape[0]
    print('条件概率：',conpro)
    # 计算后验概率的分子
    postpro = {}
    for yRange in Y:
        pro = 1
        for i in range(x.shape[0]):
            pro = pro * conpro[(i, x[i], yRange)]
        postpro[yRange] = pro * prepro[yRange]
    print ('后验概率', postpro)
    # 确定X的分类
    import operator
    return sorted(postpro.items(),   # iterable -- 可迭代对象，在python2中使用A.iteritems()，在python3中使用A.items()
           key=operator.itemgetter(1),   # key -- 主要是用来进行比较的元素，指定可迭代对象中的一个元素来进行排序，这里指基于item的value进行排序
           reverse=True)[0][0]   # reverse -- 排序规则，reverse = True 降序 ， reverse = False 升序（默认）。
# 排序结果是一个list
```