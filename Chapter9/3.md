书中关于EM算法的收敛性写得有点混淆，在此记录一下。  

EM算法的收敛性包含两方面：  
1. 似然函数序列$$P(Y|\theta^{(i)})$$的收敛  --- 无限接近于某一值  
2. 参数估计序列$$\theta^{(i)}$$的收敛   --- $$\theta^{(i)}$$和$$\theta^{(i-1)}$$之差小于某一值  

[算法过程](https://windmising.gitbook.io/lihang-tongjixuexifangfa/em/1)中指出，当**算法收敛**时迭代结束，并在后面具体指出这里的算法收到是指**参数估计序列**

在《9.2 EM算法的收敛性》证明的则是**似然函数序列**。  
通过证明：  
1. 似然函数序列是递增的  
2. 似然函数序列有上界L*  
得出：**似然函数序列收敛于某个小于L*的值**  

通过似然函数序列和参数估计序列的关系，直观上可以知道：  
1. 当参数估计序列收敛时，似然函数序列一定收敛  
2. 当似然函数序列收敛时，参数估计序列不一定收敛  

由以上可知，  
只能证明似然函数序列收敛，不能证明参数估计序列收敛，但迭代终止的条件是参数估计序列收敛   
只是证明似然函数序列收敛于不大于L* 的某一值，不能证明似然函数序列收敛于极大值点L*，但我们希望的似然函数序列尽量接近极大值  

所以，要**选取几个不同的初值，并选择最好的。**  

