$$\gamma_{jk}$$代表第j个观测值是否选择了第k个模型，1：是，0：否  
$$\hat \gamma_{jk} = E(\gamma_{jk}|y,\theta)$$代表在y和$$\theta$$已知的情况下$$\gamma_{jk}$$的条件期望。  

$$
\begin{align}
\hat \gamma_{jk} & = E(\gamma_{jk}|y,\theta) \\
& = P(\gamma_{jk}=1|y,\theta) \tag {1} \\
& = \frac{P(\gamma_{jk}=1, y_j | \theta)}{\sum_kP(\gamma_{jk}=1, y_j | \theta)} \tag {2} \\
& = \frac{P(y_j | \gamma_{jk}=1, \theta)P(\gamma_{jk}=1|\theta)}{\sum_kP(y_j | \gamma_{jk}=1, \theta)P(\gamma_{jk}=1|\theta)} \tag {3} \\
& = \frac{a_k\phi(y_j|\theta_k)}{\sum_k a_k\phi(y_j|\theta_k)}  \tag {4}
\end{align} 
$$

关于以上公式的说明：  
（1）：离散变量\gamma_{jk}的取值范围为0和1。根据[离散型变量的期望公式](https://windmising.gitbook.io/mathematics-basic-for-ml/gai-shuai-lun/expectation_variance)，得：  
$$
E(\gamma_{jk}|y,\theta) = 1 * P(\gamma_{jk}=1|y,\theta) + 0 * P(\gamma_{jk}=0|y,\theta)
$$
（2）：  
$$
\begin{align}
P(\gamma_{jk}=1|y,\theta) & = P(\gamma_{jk}=1|y_j,\theta) & 只有y_j与P(\gamma_{jk})有关，其它y都可以忽略 \\
& = \frac{P(\gamma_{jk}=1|y_j,\theta)}{\sum_k P(\gamma_{jk}|y_j=1,\theta)} & 根据\gamma_{jk}的定义，\sum_k P(\gamma_{jk}=1) = 1，与y_j和\theta无关  \\
& = \frac{P(\gamma_{jk}=1|y_j,\theta)P(y_j|\theta)}{\sum_k P(\gamma_{jk}|y_j=1,\theta)P(y_j|\theta)} & 分子分母同乘以P(y_j|\theta)  \\
& = \frac{P(\gamma_{jk}=1, y_j|\theta)}{\sum_k P(\gamma_{jk}=1, y_j|\theta)} & 贝叶斯公式，P(A|B)P(B) = P(A, B)
\end{align}
$$
（3）：贝叶斯公式，P(A, B) = P(B|A)P(A)  
（4）：$$P(\gamma_{jk}=1|\theta)$$代表选择模型k的概率，为ak  
$$P(y_j | \gamma_{jk}=1, \theta)$$代表通过第k的模型得到yj的概率，为$$\phi(y_j|\theta_k)$$