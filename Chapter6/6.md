# 根据最大熵的学习过程学习最大熵模型

最大熵的学习过程是一种数学计算方法  
最大熵模型是一种机器学习模型  
虽然都带有“最大熵”这三个字，但不是一回事  

1. 根据[最大熵模型的定义](https://windmising.gitbook.io/lihang-tongjixuexifangfa/logisticregression/4)列出最大熵模型的求最大熵公式和限制条件：  
最大熵公式：  
$$
H(P) = -\sum_{x,y} \tilde P(x) P(y|x)\log P(y|x) \\
\max H(P)
$$
限制条件：  
$$
E_P(f_i) = E_{\tilde p}(f_i)  \\
\sum_{y=0}^KP(y|x) = 1
$$

2. 将求最大值问题改写成求最小值问题。将condition换一种写法。  
$$
\min -H(P) \\
f_0: 1 - \sum_{y=0}^KP(y|x) = 0 \\
f_1: E_P(f_0) - E_{\tilde p}(f_0) = 0 \\
\cdots \\
f_{1+n}: E_P(f_n) - E_{\tilde p}(f_n) = 0
$$  
3. 根据约束条件定义拉格朗日函数  
$$
L(P, w) = -H(P) + w_0(1 - \sum_{y=0}^KP(y|x)) + \sum_{i=0}^nw_{i+1}f_i(E_P(f_i) - E_{\tilde p}(f_i))
$$
4. L(P, w)对每个$$P(y_k|x)$$求偏导，并这些偏导= 0   
$$
\frac{\partial L(P, w)}{\partial (y_k|x)} = \sum_{x, y}\tilde P(x)(\log P(y|x)+1-w_0-\sum_{i=0}^n)w_{i+1}f_i(x, y) = 0
$$
5. 根据第4步得到K个等式。通过这K个等式，解出$$P(y_1), \cdots, P(y_K)$$，这些值都是用w表达的式子  
$$
P(y|x) = \frac{exp(\sum_{i=0}^n)w_{i+1}f_i(x, y)}{exp(1-w+0)}
$$
对每个P(y|x)来说公式是一样的。  
6. 代入$$P(y_1), \cdots, P(y_K)$$到第3步中的$$L(P, w)$$，将得到新的$$L(P, w)$$  
令$$\Psi(x) = $$新的$$L(P, w)$$  
这里的$$\Psi(x)$$就叫对偶函数，同时其解记作  
$$
P_w = \arg \min_{P \in C} L(P, w) = P_w(y|x)
$$
现在要极大化对偶函数$$\Psi(x)$$。按照上一节的“最大熵学习过程”，将$$\Psi(x)$$对所有w分别求并令导入为0，即可解出w*，进而代入第5步专求出最终结果。  
但在求最大熵模型的对偶函数的极大化时，并没有使用这种方法的，而是使用了[目标函数最优化问题](https://windmising.gitbook.io/lihang-tongjixuexifangfa/option)中的方法来求w*。    
