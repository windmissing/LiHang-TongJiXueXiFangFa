adaboost的训练误差为：  
$$
ERR = \frac{分类错误的样本数}{总样本数} = \frac{\sum_{i=1}^NI(G(x_i) \neq y_i)}{N}
$$

adaboost算法最终分类器的误差界为：  
$$
ERR = \frac{1}{N}\sum_{i=1}^NI(G(x_i) \neq y_i)   \tag{1}
$$
$$
\le \frac{1}{N}\sum_{i=1}^N\exp(-y_if(x_i))    \tag{2}
$$
$$
= \prod_mZ_m    \tag{3}
$$
$$
= \prod_{m=1}^M(2\sqrt {e_m(1-e_m)})    \tag{4}
$$
$$
= \prod_{m=1}^M(2\sqrt {1-4\gamma_m^2})    \tag{5}
$$
$$
\le \exp(-2\sum_{m=1}^M\gamma_m^2)   \tag{6}
$$

说明：
（1）：ERR的定义  
（2）:  
$$
I(G(x_i) \neq y_i) =  I(G(x_i) \neq y_i) +  0
$$
当$$G(x_i) \neq y_i$$时，  
$$
y_if(x_i)\lt 0 \Rightarrow \exp(-y_if(x_i))\gt 1 = I(G(x_i) \neq y_i)
$$
当$$G(x_i) = y_i$$时，  
$$
y_if(x_i)\gt 0 \Rightarrow \exp(-y_if(x_i))\gt 1 = I(G(x_i) \neq y_i) \gt 0
$$
等式得证  
（3）：没看懂  
（4）：没看懂  
（5）：没看懂  
（6）：没看懂  