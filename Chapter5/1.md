# 决策树的模型

## 特征的选择

决定用哪个特征来划分特征空间。  
通过**信息增益**选取对训练数据具有分类能力的特征。  

[熵](https://windmising.gitbook.io/mathematics-basic-for-ml/xin-xi-lun/entropy)  

信息增益g(D,A)定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即  
$$
g(D, A) = H(D) - H(D|A)
$$

信息熵增益准则的特征选择方法：对训练数据集（或子集）D，计算其每个特征的信息增益，并比较它们的大小，选择信息增益最大的特征。  

## 决策树的生成  

生成最优决策树是NP完全问题。  
因此使用启发式方法，生成次最优决策树。  
即递归选择最优特征。  

## 决策树的修剪

生成的决策树容易发生过拟合，需要修剪。  
决策树的生成是寻找局部最优的决策树。  
决策树的修剪则是寻找全局最优的决策树。  